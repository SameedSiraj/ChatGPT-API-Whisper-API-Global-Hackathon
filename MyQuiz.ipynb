{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## To-Do (Delete Later)\n",
        "1. Install packages\n",
        "2. Whisper AI code\n",
        "3. ChatGPT Code\n",
        "4. Redis Code"
      ],
      "metadata": {
        "id": "VLgYscRAQK36"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## New Code"
      ],
      "metadata": {
        "id": "i9qaxQOlj-Sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Run this till it completes. Then refresh the page to make sure it is installed\n",
        "!pip uninstall ffmpeg-python\n",
        "!pip uninstall ffmpeg\n",
        "!pip uninstall redis\n",
        "!pip uninstall openai\n",
        "!pip uninstall git+https://github.com/openai/whisper.git\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install setuptools-rust\n",
        "!pip install redis\n",
        "!pip install openai\n",
        "!pip install ffmpeg-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6FbwNzJk0Te",
        "outputId": "ade5a002-9db7-4e7c-e358-c4697699eb75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping ffmpeg-python as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping ffmpeg as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping redis as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping openai as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Invalid requirement: 'git+https://github.com/openai/whisper.git' ignored - the uninstall command expects named requirements.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: You must give at least one requirement to uninstall (see \"pip help uninstall\")\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-7h6r_r45\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-7h6r_r45\n",
            "  Resolved https://github.com/openai/whisper.git to commit 6dea21fd7f7253bfe450f1e2512a0fe47ee2d258\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (0.56.4)\n",
            "Collecting triton==2.0.0\n",
            "  Downloading triton-2.0.0-1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpeg-python==0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Collecting tiktoken==0.3.1\n",
            "  Downloading tiktoken-0.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (1.22.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (1.13.1+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (4.65.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (9.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from ffmpeg-python==0.2.0->openai-whisper==20230314) (0.18.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/dist-packages (from tiktoken==0.3.1->openai-whisper==20230314) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.9/dist-packages (from tiktoken==0.3.1->openai-whisper==20230314) (2.27.1)\n",
            "Collecting lit\n",
            "  Downloading lit-16.0.0.tar.gz (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 KB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.10.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.25.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper==20230314) (67.6.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper==20230314) (0.39.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper==20230314) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (2.0.12)\n",
            "Building wheels for collected packages: openai-whisper, lit\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230314-py3-none-any.whl size=796926 sha256=df46f57509d60bfbdbf22a1d447f581b9e360b47da3942a316edf25572d8665d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-y7b0p887/wheels/fe/03/29/e7919208d11b4ab32972cb448bb84a9a675d92cd52c9a48341\n",
            "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-16.0.0-py3-none-any.whl size=93601 sha256=5efba2d8c24cbe732399a5c564d7b2890d4bf7cc127c4638a7ae72a600e890cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/ee/80/1520ca86c3557f70e5504b802072f7fc3b0e2147f376b133ed\n",
            "Successfully built openai-whisper lit\n",
            "Installing collected packages: lit, ffmpeg-python, triton, tiktoken, openai-whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 lit-16.0.0 openai-whisper-20230314 tiktoken-0.3.1 triton-2.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting setuptools-rust\n",
            "  Downloading setuptools_rust-1.5.2-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from setuptools-rust) (4.5.0)\n",
            "Collecting semantic-version<3,>=2.8.2\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: setuptools>=62.4 in /usr/local/lib/python3.9/dist-packages (from setuptools-rust) (67.6.0)\n",
            "Installing collected packages: semantic-version, setuptools-rust\n",
            "Successfully installed semantic-version-2.10.0 setuptools-rust-1.5.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting redis\n",
            "  Downloading redis-4.5.3-py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.6/238.6 KB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout>=4.0.2\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Installing collected packages: async-timeout, redis\n",
            "Successfully installed async-timeout-4.0.2 redis-4.5.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.2-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Installing collected packages: multidict, frozenlist, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.2 yarl-1.8.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.9/dist-packages (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from ffmpeg-python) (0.18.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code with Redis Part**"
      ],
      "metadata": {
        "id": "Nq2H0FVWwy1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import all Modules - DO NOT CHANGE\n",
        "import whisper\n",
        "import openai\n",
        "import os\n",
        "import random\n",
        "import redis\n",
        "import json\n",
        "\n",
        "#Define Variables and API Keys - DO NOT CHANGE\n",
        "model = whisper.load_model(\"base\")\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "num_questions = 0\n",
        "correct_answers = 0\n",
        "age = -1\n",
        "topic = \"\"\n",
        "\n",
        "#This Command asks the User his/her age\n",
        "print(\"What is your Age? \")\n",
        "#ageDict = model.transcribe(\"age.m4a\", fp16=False) #If you click on the folder icon located on the left side of google colaboratory, you will find the audio file 'age.m4a'. Now what I want you guys to do is upload your own recordings in their and chand the variable in this code to test if your recoding is getting converted Successfully.\n",
        "age = '14' #ageDict[\"text\"]\n",
        "print(age)\n",
        "\n",
        "#This Command asks the User his/her topic\n",
        "print(\"What Topic do you want the quiz to be on? \")\n",
        "#topicDict = model.transcribe(\"Music.m4a\", fp16=False) #If you click on the folder icon located on the left side of google colaboratory, you will find the audio file 'Music.m4a'. Now what I want you guys to do is upload your own recordings in their and chand the variable in this code to test if your recoding is getting converted Successfully.\n",
        "topic = 'Soccer' #topicDict[\"text\"]\n",
        "print(topic)\n",
        "\n",
        "#This command asks the User how many questions do they want to answer - DO NOT CHANGE\n",
        "num_questions = int(input(\"How many questions would you like to Answer? \"))\n",
        "\n",
        "# Connect to Redis\n",
        "r = redis.Redis(host='redis-14880.c15.us-east-1-2.ec2.cloud.redislabs.com', port=14880, password='b1elTNUSTLSw9MXQs3JIi3jAkV1EMrfh')\n",
        "\n",
        "#This loop goes through the number of questions that a user wants - DO NOT CHANGE\n",
        "for i in range(num_questions):\n",
        "  #The following command asks the question to the user\n",
        "  completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=[{\"role\":\"user\", \"content\": \"Generate a random easy question related to \" +topic+\" for a \"+age+\"-year-old which can be answered in one word. Don't provide the answer\"}])\n",
        "  question = completion.choices[0].message.content\n",
        "  print(completion.choices[0].message.content)\n",
        "\n",
        "  #The following command asks the user for an answer\n",
        "  user_answer = input(\"Please provide me with your answer: \")\n",
        "\n",
        "  #The following command verifies the answer with ChatGPT\n",
        "  completionOne = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=[{\"role\":\"user\", \"content\": \"Is \"+user_answer+\" a correct answer for the question: \"+question+\" Answer ONLY in True or False and be lenient. The answer need not be grammatically and fully correct\"}])\n",
        "  answer = completionOne.choices[0].message.content\n",
        "  print(completionOne.choices[0].message.content)\n",
        "\n",
        "  #The following Command checks and provides you with the score accordingly\n",
        "  if (answer == 'True' or answer == 'True.'):\n",
        "    correct_answers = correct_answers+1\n",
        "    \n",
        "  # Insert each object into Redis\n",
        "  r.lpush('my_list', json.dumps({'Topic': topic, 'Age': age, 'Question': question, 'User Answer': user_answer, 'Correct Answer': answer}))\n",
        "\n",
        "print(\"Hooray! You got \" +str(correct_answers)+ \" out of \"+str(num_questions)+\" answers right!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYqgVHmcwsUr",
        "outputId": "47b72aa3-a635-4367-ea3d-397f61525794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is your Age? \n",
            "14\n",
            "What Topic do you want the quiz to be on? \n",
            "Soccer\n",
            "How many questions would you like to Answer? 6\n",
            "What part of the body do soccer players typically use to score?\n",
            "Please provide me with your answer: goalpost\n",
            "False.\n",
            "Who won the 2018 FIFA World Cup?\n",
            "Please provide me with your answer: France\n",
            "True\n",
            "Who won the 2018 FIFA World Cup?\n",
            "Please provide me with your answer: Frabce\n",
            "False.\n",
            "What is a soccer ball made of?\n",
            "Please provide me with your answer: Rubber\n",
            "False.\n",
            "Which team won the 2018 FIFA World Cup?\n",
            "Please provide me with your answer: france\n",
            "False.\n",
            "What is the name of the ball used in soccer?\n",
            "Please provide me with your answer: football\n",
            "False.\n",
            "Hooray! You got 1 out of 6 answers right!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To Print Redis Database**"
      ],
      "metadata": {
        "id": "vGVZ8ynb8_Fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "objects_from_redis = []\n",
        "for i in range(r.llen('my_list')):\n",
        "    obj = json.loads(r.lindex('my_list', i))\n",
        "    objects_from_redis.append(obj)\n",
        "\n",
        "print(objects_from_redis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Io_i7VUd6wsD",
        "outputId": "5c7075ff-b10f-4c47-fb3d-90f5f03c8573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'Topic': 'Soccer', 'Age': '14', 'Question': 'What is the name of the ball used in soccer?', 'User Answer': 'football', 'Correct Answer': 'False.'}, {'Topic': 'Soccer', 'Age': '14', 'Question': 'Which team won the 2018 FIFA World Cup?', 'User Answer': 'france', 'Correct Answer': 'False.'}, {'Topic': 'Soccer', 'Age': '14', 'Question': 'What is a soccer ball made of?', 'User Answer': 'Rubber', 'Correct Answer': 'False.'}, {'Topic': 'Soccer', 'Age': '14', 'Question': 'Who won the 2018 FIFA World Cup?', 'User Answer': 'Frabce', 'Correct Answer': 'False.'}, {'Topic': 'Soccer', 'Age': '14', 'Question': 'Who won the 2018 FIFA World Cup?', 'User Answer': 'France', 'Correct Answer': 'True'}, {'Topic': 'Soccer', 'Age': '14', 'Question': 'What part of the body do soccer players typically use to score?', 'User Answer': 'goalpost', 'Correct Answer': 'False.'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To Refresh the Database**"
      ],
      "metadata": {
        "id": "OgksD9DX85ff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r.flushall()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brjGH97N8ZUY",
        "outputId": "f0ce445a-7b4d-437d-a462-72e93761fa78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}